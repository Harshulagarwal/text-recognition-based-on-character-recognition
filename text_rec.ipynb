{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/image1\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D,BatchNormalization\nfrom keras.layers import MaxPooling2D,Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nimport cv2\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0fb507b8d05f98844507569ba23f846a5929403c"
      },
      "cell_type": "markdown",
      "source": "# Model Building"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ed7dfb86d7e42bfb12104c6a0f261e90f202c262"
      },
      "cell_type": "code",
      "source": "# Initialising the CNN\nclassifier = Sequential()\n# Step 1 - Convolution\nclassifier.add(Convolution2D(32, (3, 3), input_shape = (50, 50,1), activation = 'relu',padding='same'))\n# Adding a second convolutional layer\n#classifier.add(BatchNormalization(axis=1))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Dropout(0.25))\n\n\nclassifier.add(Convolution2D(64, (3, 3), activation = 'relu',padding='same'))\n# Adding a second convolutional layer\nclassifier.add(Convolution2D(64, (3, 3), activation = 'relu',padding='same'))\n#classifier.add(BatchNormalization(axis=1))\n\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Dropout(0.25))\n\n\nclassifier.add(Convolution2D(128, (3, 3), activation = 'relu',padding='same'))\n# Adding a second convolutional layer\nclassifier.add(Convolution2D(128, (3, 3), activation = 'relu',padding='same'))\n#classifier.add(BatchNormalization(axis=1))\n\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Dropout(0.25))\n# Step 3 - Flattening\nclassifier.add(Flatten())\nclassifier.add(Dense(512,activation='relu'))\nclassifier.add(BatchNormalization())\nclassifier.add(Dropout(0.5))\n\n# Step 4 - Full connection\nclassifier.add(Dense(output_dim = 62, activation = 'softmax'))\n\n# Compiling the CNN\n\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\n\nclassifier.summary()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5ffdc6c72c61e3a9b0d3597428c0b7496e8810eb"
      },
      "cell_type": "markdown",
      "source": "# Fitting Image dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b4685510213dfbfeab1428518542e1af57e9e47",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   zoom_range = 0.2,\n                                   shear_range=0.2,\n\n                                  )\n\ntraining_set = train_datagen.flow_from_directory('../input/images/bmp/Bmp',\n                                                target_size = (50,50),\n                                               batch_size = 128,\n                                                 color_mode= \"grayscale\",\n                                              class_mode = 'categorical')\n\n\nclassifier.fit_generator(training_set,\n                         epochs = 50,\n                         steps_per_epoch=40,\n                         )\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e340fdf04229c9ee15d2f7d51a9de028dcf8277"
      },
      "cell_type": "markdown",
      "source": "# Preprocessing the text doc"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "114ed7cc742a0c59bedcbe8ceca62d7fec8aa4ce",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "import cv2\nfrom keras.preprocessing.image import img_to_array\nimport numpy as np\nimg=cv2.imread('../input/quotes/down.jpeg')\nimagee=img.copy()\nimg=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n\nret,img=cv2.threshold(img,180,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\nk=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n\nimg = cv2.morphologyEx(img, cv2.MORPH_OPEN, k)\nk1=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(1,1))\nimg = cv2.morphologyEx(img, cv2.MORPH_CLOSE, k)\n\nimg1=cv2.Canny(img,0,255,2)\n\ncontours, hierarchy = cv2.findContours(img1,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n\nimg2=cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\nfont = cv2.FONT_HERSHEY_SIMPLEX\n\nimg3=cv2.drawContours(img2, contours, -1, (0,255,255), 1)\nimage=[]\np=[]\nlist=['0','1','2','3','4','5','6','7','8','9']\nfor i in range(65,91):\n    list.append(chr(i))\nfor i in range(97,123):\n    list.append(chr(i))\nprint(list)\nfor c in contours:\n    x,y,w,h=cv2.boundingRect(c)\n    if w>5 and h>5:\n        \n        img4=cv2.rectangle(img3,(x,y),(x+w,y+h),(255,255,0),1)     \n        \n        i=img3[y:y+h,x:x+w]\n        i=cv2.resize(i,(50,50))\n        i=cv2.cvtColor(i,cv2.COLOR_BGR2GRAY)\n        i = i.astype(\"float\") / 255.0\n        \n        ima = img_to_array(i)\n        ima = np.expand_dims(ima, axis=0)\n        pred = classifier.predict(ima)[0]\n        #print(list[pred.argmax()],pred.max())\n        img5=cv2.putText(img4,list[pred.argmax()],(x,y+h+20), font, 0.8 ,(255,255,255),2,cv2.LINE_AA)   \n        p.append(list[pred.argmax()])\n'''for c in contours:\n    x,y,w,h=cv2.boundingRect(c)\n    if w>5 and h>5:\n        img5=cv2.putText(img4,list[pred.argmax()],(x,y+h-35), font, 0.5,(255,255,255),2,cv2.LINE_AA)        \nfrom PIL import Image, ImageTk \n#img5.show()'''\nimport matplotlib.pyplot as plt\nplt.imshow(img5)\n   ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e078debe659f1ddfd1b2506dcc5fa58c6500a399"
      },
      "cell_type": "code",
      "source": "plt.imshow(img)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c706b4a269ca5724afe93bf4693ada53d36e1b1b"
      },
      "cell_type": "markdown",
      "source": "**We can see that it matches most of the words but sometimes give error in diiferentiation of capital and small letters.**"
    },
    {
      "metadata": {
        "_uuid": "6eb234b638668cddafa362a39b9f0e562a1ba871"
      },
      "cell_type": "markdown",
      "source": "                          - - - - - - - - - - - - -- - - - - - - - - END- - - - - - - - - - - - - - - -- - - - - - - - - - - "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa3ff6f0be68127e9bca0d77a38c27d742aa6206"
      },
      "cell_type": "code",
      "source": "'''from keras.preprocessing.image import img_to_array\nimport numpy as np \nlist=['s1','s2']\nimage = cv2.imread('../input/picture/main-qimg-03de963368e748a6fb7e399772b09c48-c')\nprint(type(image))\n# pre-process the image for classification\nimage = cv2.resize(image, (50,50))\nima=image\n\nimage = image.astype(\"float\") / 255.0\nimage = img_to_array(image)\nimage = np.expand_dims(image, axis=0)\nprint(image.shape)\n\npred = classifier.predict(image)[0]\nfor i in range(2):\n    if pred[i]>0.5:\n        print(list[i],(pred[i]).astype('float32'))\n    \n\nprint(pred)\n\n#classifier.save('../input/model.h5')'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a84a101f81fe6287f3d24be1e185d08b79a1153"
      },
      "cell_type": "code",
      "source": "'''import cv2\nprint((ima.shape))\n\ngray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\nface_cascade = cv2.CascadeClassifier('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/opencv-files/haarcascade_frontalface_alt.xml')\nfaces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n(x,y,w,h)=faces[0]\nimm=gray[y:y+w, x:x+h]\nprint((gray.shape))\nimport matplotlib.pyplot as mat\nmat.plot(imm)\ncv2.waitKey()'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "60dfb948b939843aac837b4f348a7a75d4943510"
      },
      "cell_type": "code",
      "source": "'''import cv2\nf=[]\nl=[]\ndir=sorted(list(os.listdir('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data')))\nfor i in dir:\n    s=sorted(list(os.listdir('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data/'+i)))\n    for j in s:\n        print(i)\n        k=cv2.imread('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/training-data/'+i+'/'+j)\n        gray=cv2.cvtColor(k,cv2.COLOR_BGR2GRAY)\n        face_cascade=cv2.CascadeClassifier('../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/opencv-files/lbpcascade_frontalface.xml')\n        faces=face_cascade.detectMultiScale(gray,1.2,9)\n        if len(faces)>0:\n            (x,y,w,h)=faces[0]\n            face=gray[y:y+h,x:x+w]\n            f.append(face)\n            label=i\n            if label=='s1':\n                l.append(1)\n            else:\n                l.append(0)'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d99d094ecb39942036eb451783589c96a9d189ae"
      },
      "cell_type": "code",
      "source": "'''face_rec=cv2.face.LBPHFaceRecognizer_create()\nface_rec.train(f,np.array(l))\ntestimg='../input/repository/informramiz-opencv-face-recognition-python-0edc6e0/test-data/test1.jpg'\nlab,conf=face_rec.predict(testimg)'''",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}